{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb65dc3",
   "metadata": {},
   "source": [
    "# An implementation of gradient descent to optimize shallow neural network's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbbd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc706651",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f1c64",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dce7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLu(Z_test) = [[0 2 3 0]\n",
      " [1 5 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# ReLu\n",
    "def ReLu(Z):\n",
    "    \"\"\"\n",
    "    This function applies a ReLu transformation to the input Z.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "\n",
    "# test\n",
    "Z_test = np.array([[-1, 2, 3, -4], [1, 5, -3, 2]])\n",
    "print(\"ReLu(Z_test) =\", ReLu(Z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec71ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(Z_test) = [[0.73105858 0.11920292 0.04742587 0.98201379]\n",
      " [0.26894142 0.00669285 0.95257413 0.11920292]]\n"
     ]
    }
   ],
   "source": [
    "# sigmoid\n",
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    This function applies a Sigmoid transformation to the input Z.\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1 / (1 + np.exp(Z))\n",
    "\n",
    "\n",
    "# test\n",
    "Z_test = np.array([[-1, 2, 3, -4], [1, 5, -3, 2]])\n",
    "print(\"sigmoid(Z_test) =\", sigmoid(Z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44983b",
   "metadata": {},
   "source": [
    "### Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e7ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLu_prime(Z_test) = [[0 1 1 0]\n",
      " [1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def ReLu_prime(Z):\n",
    "    \"\"\"\n",
    "    This function returns the derivative of ReLu given input Z.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.where(Z < 0, 0, 1)\n",
    "\n",
    "\n",
    "# test\n",
    "Z_test = np.array([[-1, 2, 3, -4], [1, 5, -3, 2]])\n",
    "print(\"ReLu_prime(Z_test) =\", ReLu_prime(Z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5c55f",
   "metadata": {},
   "source": [
    "### Function for one step of forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed61b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_input_test = [[-1  2  3 -4]\n",
      " [ 1  5 -3  2]]\n",
      "W_test = [[ 1  2]\n",
      " [ 0 -1]\n",
      " [-3  1]]\n",
      "b_test = [[ 0]\n",
      " [-1]\n",
      " [ 2]]\n",
      "activisions = [[ 1 12  0  0]\n",
      " [ 0  0  2  0]\n",
      " [ 6  1  0 16]]\n"
     ]
    }
   ],
   "source": [
    "# one layer of forward prop\n",
    "def get_activations(A_input, W, b, activation):\n",
    "    \"\"\"\n",
    "    This function computes and returns the activisions of one layer of neurons.\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W, A_input) + b\n",
    "    return activation(Z)\n",
    "\n",
    "\n",
    "# test\n",
    "A_input_test = np.array([[-1, 2, 3, -4], [1, 5, -3, 2]])\n",
    "W_test = np.array([[1, 2], [0, -1], [-3,1]])\n",
    "b_test = np.array([[0], [-1], [2]])\n",
    "activision_test = ReLu\n",
    "print(\"A_input_test =\", A_input_test)\n",
    "print(\"W_test =\", W_test)\n",
    "print(\"b_test =\", b_test)\n",
    "print(\"activisions =\", get_activations(A_input_test, W_test, b_test, activision_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba76c4",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1596e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (2, 10)\n"
     ]
    }
   ],
   "source": [
    "# simulate m examples of nx dimension column vector, X, with each element being a random value in [-0.5, 0.5] following\n",
    "# a uniform distribution\n",
    "nx = 2\n",
    "m = 10\n",
    "X = np.random.rand(nx, m) - 0.5\n",
    "print(\"X.shape =\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd2a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for simulated y, for a 2-layer shallow network, with n1=3 and n2=1\n",
    "W1 = np.array([[-0.5, 0.5], [-1, 0.5], [0.5, 1]])\n",
    "b1 = np.array([[0], [-1], [0.5]])\n",
    "W2 = np.array([[1, -1, -0.5]])\n",
    "b2 = np.array([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeed1baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2.shape = (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "A1 = get_activations(A_input=X, W=W1, b=b1, activation=ReLu)\n",
    "A2 = get_activations(A_input=A1, W=W2, b=b2, activation=sigmoid)\n",
    "print(\"A2.shape =\", A2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1589f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape = (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# simulate m examples of 1-dimensional column vector, Y\n",
    "Y = np.where(np.random.rand(1, m) < A2, 1, 0)\n",
    "print(\"Y.shape =\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421cc1c",
   "metadata": {},
   "source": [
    "# Fit a 2-layer neural network to the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49f4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
